import fitz  # PyMuPDF
import re
from datetime import datetime, timedelta,date
import unicodedata
from collections import defaultdict
def extract_text(PDF_path):
    doc = fitz.open(PDF_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text
# PDFã‹ã‚‰1æ–‡å­—ãšã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã¨åº§æ¨™ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
def extract_chars(PDF_path, page_mun=1):
    doc = fitz.open(PDF_path)
    page = doc[page_mun-1]
    rawdict = page.get_text("rawdict")

    chars_list = []

    for block in rawdict["blocks"]:
        if "lines" in block:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ã¿å¯¾è±¡
            for line in block["lines"]:
                for span in line["spans"]:
                    for c in span["chars"]:  # ã“ã“ã§1æ–‡å­—ãšã¤
                        x0, y0, x1, y1 = c["bbox"]
                        chars_list.append({
                            "text": c["c"],
                            "area": (x0, y0, x1, y1)
                        })

    
    print(f"chars_list")
    for a in chars_list[:5]:
        print(f"ãƒ»{a}")
    
    return chars_list

def extract_names_from_PDF_A(PDF_path):
    text = extract_text(PDF_path)

    # æ¼¢å­—ãƒ»ã²ã‚‰ãŒãªãƒ»é•·éŸ³ç¬¦å·ï¼ˆãƒ¼ï¼‰ã‚’è¨±å®¹
    # è‹—å­—ï¼šæ¼¢å­—1ï½5æ–‡å­—
    # åï¼šæ¼¢å­—ãƒ»ã²ã‚‰ãŒãªãƒ»é•·éŸ³ç¬¦å· 1ï½5æ–‡å­—
    # ã‚¹ãƒšãƒ¼ã‚¹ã¯å…¨è§’ãƒ»åŠè§’ã©ã¡ã‚‰ã‚‚OK
    pattern = re.compile(
        r"([\u4E00-\u9FFF]{1,5})[ ã€€]{1}([\u4E00-\u9FFF\u3040-\u309Fãƒ¼]{1,5})"
    )

    matches = pattern.findall(text)

    full_names = []
    for last, first in matches:
        full_name = f"{last}\u3000{first}"
        # å½¹è·ãªã©ã®å‰ç½®ãé™¤å¤–
        if re.match(r"^(ä¸»|å‰¯|åŠ©|ä»£\d?|æŒ¯\d?)", full_name):
            continue 
        full_names.append(full_name)
    full_names=sorted(full_names)

    
    for a in full_names:
        print("â˜†", a)
    return full_names

def extract_text_top_area(PDF_path, height_ratio=0.1):
    """
    PDFã®1ãƒšãƒ¼ã‚¸ç›®ã®ä¸Šéƒ¨ï¼ˆãƒšãƒ¼ã‚¸é«˜ã•ã®height_ratioåˆ†ï¼‰ã ã‘ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã€‚
    """
    doc = fitz.open(PDF_path)
    page = doc[0]  # 1ãƒšãƒ¼ã‚¸ç›®ã‚’å¯¾è±¡

    rect = page.rect
    top_rect = fitz.Rect(rect.x0, rect.y0, rect.x1, rect.y0 + rect.height * height_ratio)

    # æŒ‡å®šçŸ©å½¢ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§å–å¾—ã—ã¦çµåˆï¼‰
    blocks = page.get_text("blocks")  # å„ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯: (x0, y0, x1, y1, "text", block_no, block_type)
    texts = []
    for b in blocks:
        b_rect = fitz.Rect(b[:4])
        if b_rect.intersects(top_rect):
            texts.append(b[4])

    return "\n".join(texts)
def get_schedule_month_from_PDF_A(PDF_path):
    text = extract_text_top_area(PDF_path, height_ratio=0.15)  # ä¸Šéƒ¨15%ã‚’æŠ½å‡º

    # ä¾‹ï¼šã€Œ2025 å¹´ 8 æœˆã€ã‚„ã€Œ2025å¹´8æœˆã€ã®å½¢å¼ã‚’æƒ³å®š
    match = re.search(r"(\d{4})\s*å¹´\s*(\d{1,2})\s*æœˆ", text)
    if match:
        year = int(match.group(1))
        month = int(match.group(2))
        print(f"æŠ½å‡ºã•ã‚ŒãŸå¹´æœˆ: {year}å¹´{month}æœˆ")
        return year, month
    raise ValueError("å¹´æœˆæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


def find_word_positions(PDF_path, keyword,search_height=200):
    """
    PDFå†…ã®æŒ‡å®šæ–‡å­—ã®åº§æ¨™(x0, y0, x1, y1)ã‚’ã™ã¹ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤ã¯ãƒšãƒ¼ã‚¸ã”ã¨ã®ãƒªã‚¹ãƒˆ: [(page_num, x0, y0, x1, y1), ...]
    """
    # PDFã‚’é–‹ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹
    doc = fitz.open(PDF_path)
    positions = []
    name_pattern=re.compile(r"([\u4E00-\u9FFF]{1,5})[ ã€€]{1}([\u4E00-\u9FFF\u3040-\u309Fãƒ¼]{1,5})")
    m=name_pattern.match(keyword)


    for page_num, page in enumerate(doc, start=1):
        words = page.get_text("words")
        for x0, y0, x1, y1, text, *_ in words:
            if m: #keywordãŒåå‰ã®æ™‚
                last_name = m.group(1)  # è‹—å­—
                first_name = m.group(2)  # åå‰

                if y1 <= search_height and text == keyword:   #keywordãŒå®Œå…¨ä¸€è‡´
                   positions.append((page_num, x0, y0, x1, y1))
                else:#keywordã¨ä¸€è‡´ç„¡ã—
                    if y1 <= search_height and text == last_name: #è‹—å­—ã§æ¤œç´¢ã—ã¦Hit
                         
                         positions.append((page_num, x0, y0, x1, y1))
                    else:
                        if y1 <= search_height and text == first_name: #åå‰ã§æ¤œç´¢
                            positions.append((page_num, x0, y0, x1, y1))

             
                     
                
            else: #keywordãŒåå‰ã§ã¯ãªã„ã¨ã
               if y1 <= search_height and text == keyword:   #keywordãŒå®Œå…¨ä¸€è‡´
                    positions.append((page_num, x0, y0, x1, y1))  
               
    print(f"[DEBUG] '{keyword}' ã®ä½ç½®: {positions}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    return words,positions


def search_keyword_in_pdf(pdf_path, keyword, search_height=200):
    doc = fitz.open(pdf_path)
    positions = []

    # åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®šï¼ˆè‹—å­—1ã€œ5æ¼¢å­— + ã‚¹ãƒšãƒ¼ã‚¹ + åå‰1ã€œ5ï¼‰
    pattern_name = re.compile(r"^([\u4E00-\u9FFF]{1,5})[ ã€€]{1}([\u4E00-\u9FFF\u3040-\u309Fãƒ¼]{1,5})$")
    m = pattern_name.match(keyword)

    if m:
        last_name, first_name = m.groups()
    else:
        last_name = first_name = None

    for page_num, page in enumerate(doc, start=1):
        words = page.get_text("words")  # [(x0, y0, x1, y1, text, ...), ...]

        if m:  # åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³
            full_hits = []
            last_hits = []
            first_hits = []

            for x0, y0, x1, y1, text, *_ in words:
                if y1 > search_height:
                    continue
                if text == keyword:#ãƒ•ãƒ«ãƒãƒ¼ãƒ ãƒ’ãƒƒãƒˆæ™‚ã¯full_hitsã«æ ¼ç´
                    full_hits.append((page_num, x0, y0, x1, y1))
                elif text == last_name:#è‹—å­—ãƒ’ãƒƒãƒˆæ™‚ã¯last_hitsã«æ ¼ç´
                    last_hits.append((page_num, x0, y0, x1, y1))
                elif text == first_name:#åå‰ãƒ’ãƒƒãƒˆæ™‚ã¯first_hitsã«æ ¼ç´
                    first_hits.append((page_num, x0, y0, x1, y1))

            if len(full_hits)==1:  # ãƒ•ãƒ«ãƒãƒ¼ãƒ ã§ãƒ’ãƒƒãƒˆ
                positions.extend(full_hits)
            elif len(full_hits)>1:
                 print(f"âš  åŒå§“åŒå: {keyword}")
            elif len(last_hits) == 1:  # è‹—å­—1ä»¶ã®ã¿
                positions.extend(last_hits)
            elif len(last_hits) > 1:  # è‹—å­—2ä»¶ä»¥ä¸Š
                if len(first_hits) == 1:
                    positions.extend(first_hits)
                elif len(first_hits) > 1:
                    print(f"âš  åŒå§“åŒå: {keyword}")
                    positions.extend(first_hits)  # å¿…è¦ãªã‚‰å…¨ä»¶è¿½åŠ 

        else:  # åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã˜ã‚ƒãªã„
            for x0, y0, x1, y1, text, *_ in words:
                if y1 > search_height:
                    continue
                if text == keyword:
                    positions.append((page_num, x0, y0, x1, y1))
    print(f"{keyword}ã®åº§æ¨™ã¯{positions}")
    return positions


def extract_text_in_xrange(PDF_path,  x_min, x_max,page_num=1,):
    """
    æŒ‡å®šãƒšãƒ¼ã‚¸ã®æŒ‡å®šxç¯„å›²ã«ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¸Šã‹ã‚‰é †ã«è¿”ã™ã€‚
    """
    doc = fitz.open(PDF_path)
    page = doc[page_num - 1]

    words = page.get_text("words")
    # Xåº§æ¨™ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿
    filtered = [
        (y0, text) for x0, y0, x1, y1, text, *_ in words
        if x0 >= x_min and x1 <= x_max
    ]
    # Yåº§æ¨™é †ã«ä¸¦ã¹ã¦ãƒ†ã‚­ã‚¹ãƒˆã ã‘è¿”ã™
    filtered.sort(key=lambda w: w[0])
    #print(f"[DEBUG] keywordã¨åŒåˆ—ã®ãƒ†ã‚­ã‚¹ãƒˆ: {filtered}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    return [{"text": text, "y": y} for y, text in filtered]

def pick_up_date_line(PDF_path,sub=10, add=-5):
    words,position=find_word_positions(PDF_path, "åå‰",search_height=200)
    # position ã¯ [(page_num, x0, y0, x1, y1)] å½¢å¼ã‚’æƒ³å®š
    y0 = position[0][2]
    y1 = position[0][4]
    print(f"y0:{y0}, y1:{y1}")
    y_min=y0-sub
    y_max=y1+add
    date_line=[]
    seen_texts = set()  # å‡ºç¾æ¸ˆã¿ã® text ã‚’è¨˜éŒ²ã™ã‚‹é›†åˆ
    for word in words:
        x0, y0, x1, y1, text,*_=word
        if y0>=y_min and y1<=y_max:
            if text not in seen_texts:  # åˆã‚ã¦å‡ºãŸ text ã ã‘è¿½åŠ 
                date_line.append({"text": text, "area": (x0, y0, x1, y1)})
                seen_texts.add(text)    
    # print(f"date_line")
    # for a in date_line:
    #     print(f"ãƒ»{a}")
    return date_line

def pick_up_row_text(PDF_path,keyword,page_num=1,sub=5,add=-3,search_height=800):
    all_text=extract_chars(PDF_path, page_mun=page_num)
    words,keyword_position=find_word_positions(PDF_path, keyword,search_height=search_height)
    print(f"keyword_position:{keyword_position}")
    y0=keyword_position[0][2]
    y1=keyword_position[0][4]
    print(f"y0:{y0}, y1:{y1}")
    y_min=y0-sub
    y_max=y1+add

    target_row=[]
    for text in all_text:
        if text["area"][1]>=y_min and text["area"][3]<=y_max:
            #print(f"ãƒ»{text}")
            target_row.append({"text":text["text"],"area":text["area"]})
    return target_row

def merge_target_row_dataline(PDF_path, keyword):
    target_row=pick_up_row_text(PDF_path, keyword,page_num=1, sub=5,add=-3,search_height=800)
    date_line = pick_up_date_line(PDF_path,sub=10, add=-5)
    
    """     print("date_line")
    for a in date_line:
        print(f"ãƒ»{a}")
    print("target_row")
    for a in target_row:
        print(f"ãƒ»{a}")
     """
    merged=[]
    for d in date_line:
        d_x0 = d["area"][0]-10
        d_x1 = d["area"][2]+10
        for t in target_row:
            t_x0 = t["area"][0]
            t_x1 = t["area"][2]
            # Xåº§æ¨™ãŒè¿‘ã„ target_row è¦ç´ ã‚’æ¢ã™ï¼ˆå·®ãŒæœ€å°ã®ã‚‚ã®ï¼‰
            if t_x0>d_x0 and t_x1<d_x1:
                new_t = t.copy()          # è¾æ›¸ã‚’ã‚³ãƒ”ãƒ¼
                new_t["date"] = d["text"] # date ã‚’è¿½åŠ 
                merged.append(new_t)
    # print("merged")
    # for a in merged:
    #     print(f"ãƒ»{a}")

    grouped = defaultdict(list)
    # æ—¥ä»˜ã”ã¨ã« grouped ã«æ ¼ç´
    for m in merged:   
        grouped[m["date"]].append(m)

    merged_date = []

    # grouped ã‚’å‡¦ç†
    for date, items in grouped.items():
        # x åº§æ¨™é †ã«ä¸¦ã¹ã‚‹
        items = sorted(items, key=lambda it: it["area"][0])

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’é€£çµ
        merged_text = "".join([it["text"] for it in items])

        # æœ€å°ãƒ»æœ€å¤§åº§æ¨™ã‚’å–ã£ã¦å›²ã‚€
        x0 = min(it["area"][0] for it in items)
        y0 = min(it["area"][1] for it in items)
        x1 = max(it["area"][2] for it in items)
        y1 = max(it["area"][3] for it in items)

        # merged_date ã«è¿½åŠ 
        merged_date.append({
            "date": date,
            "text": merged_text,
            "area": (x0, y0, x1, y1),
            
        })


    print("merged_date")
    for a in merged_date:
        print(f"ãƒ»{a}")


    return merged_date    

def extract_schedule_from(PDF_path, keyword):
    merged_date=merge_target_row_dataline(PDF_path, keyword)
    year_A,month_A=get_schedule_month_from_PDF_A(PDF_path)
    convert_for_google = []
    timezone = "Asia/Tokyo"  # æ—¥æœ¬æ™‚é–“

    for m in merged_date:
        day = int(m["date"])
        start=date(year_A, month_A, day).strftime("%Y-%m-%d")
        end=(date(year_A, month_A, day)+ timedelta(days=1)).strftime("%Y-%m-%d")
        if m["text"]=="ä»£ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "ä»£æ›¿ä¼‘æ—¥",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})
        elif m["text"]=="å¹´ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "å¹´æ¬¡ä¼‘æš‡",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})
        elif m["text"]=="æŒ¯ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "æŒ¯æ›¿ä¼‘æ—¥",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})
        elif m["text"]=="Ã—":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "æ¥­å‹™å¯¾å¿œä¸å¯",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})
        elif m["text"]=="â‘¯":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "å½“ç›´",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})
        elif m["text"]=="1":
            convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                "end": {"date": end,"timeZone": timezone},
                                "summary": "1st on call",
                                "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["text"]=="2":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "2nd on call",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
      
        elif m["text"]=="ï¼¡ï¼­ä¼‘":
                end = f"{start}T17:15:00"
                start = f"{start}T13:22:30"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "åˆå¾Œå‡ºå‹¤ï¼ˆåˆå‰ä¼‘ï¼‰",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{keyword}"})

        elif m["text"]=="ï¼°ï¼­ä¼‘":
                end = f"{start}T12:22:30"
                start = f"{start}T08:30:00"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "åˆå‰å‡ºå‹¤ï¼ˆåˆå¾Œä¼‘ï¼‰",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["text"]=="æ˜":
                end = f"{start}T08:30:00"
                start = f"{start}T00:00:00"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "å½“ç›´æ˜ã‘",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
                
        else:
            #ä½•ã‚‚è¿½åŠ ã—ãªã„ã‚ˆã†ã«ã™ã‚‹
             pass
    print("convert_for_google")
    for a in convert_for_google:
        print(f"ãƒ»{a}")
    return convert_for_google


# æŒ‡å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åˆ—ã‚’æŠ½å‡ºã—ã€å€‹ã€…ã®yåº§æ¨™ã‚’å–å¾—
def extract_column_and_yrange_from_PDF_A(PDF_path,keyword,search_height=200,sub=10,add=10):
    
    find_column= search_keyword_in_pdf(PDF_path,keyword, search_height=search_height)
    print(f"[DEBUG] {keyword} æ–‡å­—ã®åº§æ¨™: {find_column}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    x = find_column[0][1]  # keywordã®xåº§æ¨™ã‚’å–å¾—
    x_min=x- sub
    x_max=x+ add
    target_column=extract_text_in_xrange(PDF_path, x_min, x_max, page_num=1)
    target_column = [item for item in target_column if item['text'] != keyword]
    print(f"[DEBUG] {keyword} åˆ—ã®ãƒ†ã‚­ã‚¹ãƒˆ: {target_column}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    return target_column

# æŒ‡å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¡Œã‚’æŠ½å‡ºã—ã€å€‹ã€…ã®xåº§æ¨™ã‚’å–å¾—
def extract_row_and_xrange_from_PDF_A(PDF_path,keyword,search_height=300,sub=10,add=10):
    find_row= search_keyword_in_pdf(PDF_path,keyword, search_height=search_height)
    print(f"[DEBUG] {keyword} æ–‡å­—ã®åº§æ¨™: {find_row}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    y = find_row[0][2]  # keywordã®yåº§æ¨™ã‚’å–å¾—
    #å–å¾—ã—ãŸã„æƒ…å ±ãŒå–å¾—ã§ãã‚‹yç¯„å›²ã‚’å¾®èª¿æ•´
    y_min=y-sub
    y_max=y+add
    target_row=extract_text_in_yrange(PDF_path, y_min, y_max, page_num=1)
    target_row = [item for item in target_row if item['text'] != keyword]
    print(f"[DEBUG] {keyword} è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆ: {target_row}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    return target_row



#å‹¤å‹™è¡¨ã®æŠ½å‡ºç”¨é–¢æ•°
def extract_schedule_from_PDF_A(PDF_path, selected_name,x_tolerance=5):

    date_line = extract_row_and_xrange_from_PDF_A(PDF_path,"åå‰",search_height=200,sub=20,add=10)
    target_line = extract_row_and_xrange_from_PDF_A(PDF_path,selected_name,search_height=800,sub=10,add=10)
    

    for i, cell in enumerate(target_line):
        if re.search(r"(æ—¥|å¤œ|æ—¥å¤œ|å‹¤å‹™|å‹¤)", cell["text"]):
            target_line = target_line[i + 1:]
            print(f"[DEBUG] Found work start position: \n{target_line}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
            break
    else:
        raise ValueError("å‹¤å‹™ãƒãƒ¼ã‚¯é–‹å§‹ä½ç½®ï¼ˆæ—¥å¤œãªã©ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    year_A,month_A=get_schedule_month_from_PDF_A(PDF_path)

    
    
    
    print(f"[DEBUG] æ—¥ä»˜åˆ—: {date_line}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    print(f"[DEBUG] {selected_name}åˆ—: {target_line}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    

    #date_lineã¨target_lineã‚’çµ±åˆã™ã‚‹
    merged = []
    
    for d in date_line:
        d_x = d["x"]
        # xåº§æ¨™ãŒè¿‘ã„ target_line è¦ç´ ã‚’æ¢ã™ï¼ˆå·®ãŒæœ€å°ã®ã‚‚ã®ï¼‰
        candidates = [(abs(n["x"] - d_x), n) for n in target_line]
        candidates = [c for c in candidates if c[0] <= x_tolerance]

        if candidates:
            # å·®ãŒæœ€å°ã®ã‚‚ã®ã‚’é¸æŠ
            candidates.sort(key=lambda x: x[0])
            closest = candidates[0][1]
            merged.append({"date_text": d["text"], 
                           "work_mark": closest["text"]})
        else:
            # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° None
            merged.append({"date_text": d["text"], 
                           "work_mark": None})
    print(f"merged:\n{merged}")
    
    #merged["work_mark"]ã®ç¨®é¡ã”ã¨ã«ãƒªã‚¹ãƒˆå†…ã‚’æ›¸ãæ›ãˆä¸”ã¤google calenderç”¨ã«ã‹ãˆã‚‹
    convert_for_google = []
    timezone = "Asia/Tokyo"  # æ—¥æœ¬æ™‚é–“
    for m in merged:
        day = int(m["date_text"])
        start=date(year_A, month_A, day).strftime("%Y-%m-%d")
        end=(date(year_A, month_A, day)+ timedelta(days=1)).strftime("%Y-%m-%d")
        if m["work_mark"]=="1":
            convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                "end": {"date": end,"timeZone": timezone},
                                "summary": "1st on call",
                                "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="2":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "2nd on call",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="ä»£ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "ä»£æ›¿ä¼‘æ—¥",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="å¹´ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "å¹´æ¬¡ä¼‘æš‡",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="æŒ¯ä¼‘":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "æŒ¯æ›¿ä¼‘æ—¥",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="Ã—":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "æ¥­å‹™å¯¾å¿œä¸å¯",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="â‘¯":
                convert_for_google.append({"start": {"date": start,"timeZone": timezone},
                                    "end": {"date": end,"timeZone": timezone},
                                    "summary": "å½“ç›´",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="ï¼¡ï¼­ä¼‘":
                end = f"{start}T17:15:00"
                start = f"{start}T13:22:30"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "åˆå¾Œå‡ºå‹¤ï¼ˆåˆå‰ä¼‘ï¼‰",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="ï¼°ï¼­ä¼‘":
                end = f"{start}T12:22:30"
                start = f"{start}T08:30:00"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "åˆå‰å‡ºå‹¤ï¼ˆåˆå¾Œä¼‘ï¼‰",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
        elif m["work_mark"]=="æ˜":
                end = f"{start}T08:30:00"
                start = f"{start}T00:00:00"
                
                convert_for_google.append({"start": {"dateTime": start,"timeZone": timezone},
                                    "end": {"dateTime": end,"timeZone": timezone},
                                    "summary": "å½“ç›´æ˜ã‘",
                                    "description": f"å‹¤å‹™è¡¨:MAIN è·å“¡:{selected_name}"})
                
        else:
            #ä½•ã‚‚è¿½åŠ ã—ãªã„ã‚ˆã†ã«ã™ã‚‹
             pass




    # selected_nameã®è‹—å­—ã ã‘æŠ½å‡º
    if not convert_for_google:
        print(f"[DEBUG] {selected_name} ã®å‹¤å‹™äºˆå®šã¯ç„¡ã—")
        
    else:
        print(f"[DEBUG] {selected_name} ã®HDæ—©å‡ºå‹¤å‹™ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(convert_for_google)}")

    for a in convert_for_google[:5]:
        print("â˜†", a)

    return convert_for_google

#file_PDF_Bã‹ã‚‰åå‰ã ã‘å–ã‚Šå‡ºã™é–¢æ•°
#testç”¨
if __name__ == "__main__":
    import os

    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    upload_dir = "uploads"
    test_filename = "å‹¤å‹™è¡¨2025.9ver3.1.pdf"
    #test_filename = "è¡€æ¶²æµ„åŒ–ã‚»ãƒ³ã‚¿ãƒ¼ã€€æ—©å‡ºå‹¤å‹™è¡¨ã€€2025å¹´ 8æœˆ.pdf"
    test_path = os.path.join(upload_dir, test_filename)
    search_height=800


    test_name="æˆ¸ç”°ã€€ä¿®ä¸€"
    print("ğŸ“„ [TEST] ãƒ•ã‚¡ã‚¤ãƒ«:", test_path)


    print(fitz.__doc__)
    print(fitz.__version__)
    
    #extract_chars(test_path)
    #pick_up_date_line(test_path,sub=10, add=-5)
    #extract_names_from_PDF_A(test_path)
    #search_keyword_in_pdf(test_path, test_name, search_height)
    #find_word_positions(test_path,test_name,search_height=800)
    #pick_up_row_text(test_path,test_name,page_num=1,sub=5,add=-3,search_height=800)
    merge_target_row_dataline(test_path,test_name)
    extract_schedule_from(test_path, test_name)
    #extract_column_and_yrange_from_PDF_A(test_path,"åå‰",sub=40,add=30)
    #extract_row_and_xrange_from_PDF_A(test_path,"åå‰",search_height=200,sub=20,add=10)
    #extract_row_and_xrange_from_PDF_A(test_path,"å¤§æ±Ÿã€€ç›´ç¾©",search_height=500,sub=10,add=10)
    #extract_schedule_from_PDF_A(test_path,test_name,x_tolerance=6)
    #extract_names_from_PDF_A(test_path)

    #extract_month_from_PDF_A(test_path)
    
    
